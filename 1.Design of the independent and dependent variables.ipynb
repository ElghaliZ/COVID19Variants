{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions to be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Region of the sequence\n",
    "def get_region(x):\n",
    "    if len(x)>2:\n",
    "        return(x[2])\n",
    "    else:\n",
    "        return(None)\n",
    "\n",
    "# Week day of the sequence\n",
    "def get_sunday(date_in):\n",
    "    today = date_in\n",
    "    next_sunday = today + datetime.timedelta(days=6-today.weekday(), weeks=0)\n",
    "    return(next_sunday)\n",
    "\n",
    "def remove_from_list(L):\n",
    "    if \" \" in L:\n",
    "        return(L.remove(\" \"))\n",
    "    else:\n",
    "        return(L)\n",
    "\n",
    "# Dynamic feature: mean change over time\n",
    "def mean_change(x):\n",
    "    x = np.asarray(x)\n",
    "    return (x[-1] - x[0]) / (len(x) - 1) if len(x) > 1 else np.NaN\n",
    "\n",
    "# Mean second derivative\n",
    "def mean_second_derivative_central(x):\n",
    "    x = np.asarray(x)\n",
    "    return (x[-1] - x[-2] - x[1] + x[0]) / (2 * (len(x) - 2)) if len(x) > 2 else np.NaN\n",
    "\n",
    "# Relative evolution\n",
    "def relative_first_derivative(x):\n",
    "    t = list(x)\n",
    "    first_d = [(t[i+1]-t[i])/t[i] for i in range(len(t)-1) if t[i]!= 0]\n",
    "    if len(first_d) == 0:\n",
    "        return([0],0)\n",
    "    else:\n",
    "        mean_first_d = sum(first_d)/len(first_d)\n",
    "        return (first_d, mean_first_d)\n",
    "\n",
    "# Entopy with the proportion of each variant\n",
    "def entropy(x):\n",
    "    v_tot = sum(x)\n",
    "    prop = x/v_tot\n",
    "    ent = sum([-p*np.log(p) for p in prop if p!=0])\n",
    "    return(ent)\n",
    "\n",
    "#Jaccard distance between two variants based on their respective mutations\n",
    "def jaccard_distance(L1, L2):\n",
    "    intersection = 0\n",
    "    union = 0\n",
    "    n = len(L1)\n",
    "    for i in range(n):\n",
    "        if (L1[i] == 1) and (L1[i] == L2[i]):\n",
    "            intersection+=1\n",
    "        if (L1[i] == 1) or (L2[i] == 1):\n",
    "            union+=1\n",
    "    j_distance = 1-intersection/union\n",
    "    return(j_distance)\n",
    "\n",
    "def absolute_distance(L1, L2):\n",
    "    distance = np.absolute(np.subtract(L1,L2)).sum()\n",
    "    return(distance)\n",
    "\n",
    "def get_country(x):\n",
    "    if len(x)>=2:\n",
    "        return(x[1])\n",
    "    else:\n",
    "        return(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the biological feature for the variant in its respective country\n",
    "#c = country\n",
    "#variants_country = sequences in country\n",
    "#seq_count_per_week_pivot = weekly count of sequences per variant in country\n",
    "#var = variant\n",
    "#n_weeks = number of observation weeks\n",
    "#threshold_substitution = threshold of the proportion of sequences for which a mutation appears to associate it with the variant\n",
    "#threshold_seq = threshold of the number of sequences of a variant to consider it in a country\n",
    "#country_cases = number of cases per country\n",
    "\n",
    "def get_biological_evolution(c, variants_country,seq_count_per_week_pivot,var,n_weeks,threshold_substitution, threshold_seq, country_cases):\n",
    "\n",
    "    #Extracting all the variants and their sequence counts\n",
    "    list_variants = variants_country[\"Pango lineage\"].unique()\n",
    "    sequences_all = variants_country[variants_country[\"Pango lineage\"] == var]\n",
    "    seq_count = sequences_all.groupby(\"week_date\")['Accession ID'].count().reset_index().rename(columns = {'Accession ID':\"seq_count\"})\n",
    "    l_count = list(seq_count[\"seq_count\"])\n",
    "    seq_count[\"seq_count_2\"] = l_count[1:]+[l_count[len(l_count)-1]]\n",
    "\n",
    "    ### Significant count of sequences in the week of detection and following one\n",
    "    seq_count_sig = seq_count[(seq_count[\"seq_count\"]>=threshold_seq) & (seq_count[\"seq_count_2\"]>=threshold_seq)]\n",
    "    var_country_df = pd.DataFrame([c], columns = [\"country\"])\n",
    "    var_country_df[\"variant\"] = var\n",
    "    if len(seq_count_sig) == 0:\n",
    "        return(var_country_df)\n",
    "    \n",
    "    else:\n",
    "        ### Selecting all sequences during observation period\n",
    "        min_date = seq_count_sig[\"week_date\"].min()\n",
    "        max_date = min_date + datetime.timedelta(days=n_weeks*7)\n",
    "        sequences_first = sequences_all[(sequences_all[\"week_date\"]<= max_date) & (sequences_all[\"week_date\"] >= min_date)]\n",
    "        sequences_first['substitutions_list'] = sequences_first['AA Substitutions'].astype(\"str\").apply(lambda x:x.replace(\" \",\"\").replace(\")\",\",\").replace(\"(\",\"\").split(\",\")[:-1])\n",
    "\n",
    "        ### Getting the genetic mutations\n",
    "        all_substitutions_list_unique = list(set(sequences_first['substitutions_list'].sum()))\n",
    "        dict_substitutions = dict([[p,0] for p in all_substitutions_list_unique])\n",
    "        if len(dict_substitutions) == 0:\n",
    "            return(var_country_df)\n",
    "        else:\n",
    "            n_seq = len(sequences_first)\n",
    "            for i in range(n_seq):\n",
    "                sub_var = sequences_first['substitutions_list'].iloc[i]\n",
    "                for s in sub_var:\n",
    "                        dict_substitutions[s] += 1\n",
    "            ### Getting ratio of presence of each mutation in the variant's sequences\n",
    "            df_substitutions = pd.DataFrame.from_dict(dict_substitutions, orient = \"index\").reset_index().rename(columns = {\"index\":\"substitutions\",0:\"sub_count\"})\n",
    "            df_substitutions[\"sub_ratio\"] = df_substitutions[\"sub_count\"]/n_seq\n",
    "            \n",
    "            ### Considering the mutations that appear with a ration higher than the threshold of substitution\n",
    "            df_substitutions = df_substitutions[df_substitutions[\"sub_ratio\"]>threshold_substitution]\n",
    "            all_sub = df_substitutions[\"substitutions\"]\n",
    "            sub_ratio = df_substitutions[\"sub_ratio\"]\n",
    "            for i in range(len(all_sub)):\n",
    "                var_country_df[all_sub.iloc[i]] = 1 # Could be replaced by sub_ratio.iloc[i] to get the ratio of sequences where this substitution appears\n",
    "\n",
    "            ### Computing for the country the evolution of the proportions of each variant during the period of time when the variant appeared\n",
    "            seq_count_period = seq_count_per_week_pivot[(seq_count_per_week_pivot[\"week_date\"]<= max_date) & (seq_count_per_week_pivot[\"week_date\"] >= min_date)].reset_index()\n",
    "            seq_count_period_cases = pd.merge(seq_count_period, country_cases, on = \"week_date\")\n",
    "            list_variants = list(list_variants)\n",
    "            list_variants = [v for v in list_variants if (v!= \"None\" and str(v)!= 'nan')]\n",
    "            seq_count_period[\"number_sequences\"] = seq_count_period[list_variants].sum(axis = 1)\n",
    "\n",
    "            ### Getting the dynamics of the variant and the other variants when the variant started \n",
    "            var_ratio = seq_count_period[var]/seq_count_period[\"number_sequences\"]\n",
    "            m_change_val = mean_change(var_ratio)\n",
    "            m_second_derivative_central = mean_second_derivative_central(var_ratio)\n",
    "            r_first_derivative_val = relative_first_derivative(var_ratio)\n",
    "\n",
    "            r_first_derivative = r_first_derivative_val[0]\n",
    "            r_first_derivative_mean = r_first_derivative_val[1]\n",
    "\n",
    "            ### Enriching the table with variants proportions, their entropy and evolution\n",
    "            list_variants_1 = [v for v in list_variants if v!= var]\n",
    "            col = list_variants+[\"number_sequences\"]\n",
    "            sum_seq_over_period = seq_count_period[col].sum(axis = 0)\n",
    "            if len(list_variants_1)>0:\n",
    "                dominant_1 = sum_seq_over_period[list_variants_1].idxmax()\n",
    "                prop_dominant_1 = sum_seq_over_period[dominant_1].max()/sum_seq_over_period[\"number_sequences\"]\n",
    "                var_country_df[\"dominant_1\"] = dominant_1\n",
    "                var_country_df[\"prop_dominant_1\"] = prop_dominant_1\n",
    "\n",
    "            list_variants_2 = [v for v in list_variants_1 if v!= dominant_1]\n",
    "            if len(list_variants_2)>0:\n",
    "                dominant_2 = sum_seq_over_period[list_variants_2].idxmax()\n",
    "                prop_dominant_2 = sum_seq_over_period[dominant_2].max()/sum_seq_over_period[\"number_sequences\"]\n",
    "                var_country_df[\"dominant_2\"] = dominant_2\n",
    "                var_country_df[\"prop_dominant_2\"] = prop_dominant_2\n",
    "\n",
    "            var_entropy = entropy(sum_seq_over_period[list_variants].values)\n",
    "            var_country_df[\"variants_entropy\"] = var_entropy\n",
    "\n",
    "            ratio_week = \"ratio_week_\"\n",
    "            for i in range(len(var_ratio)):\n",
    "                var_country_df[ratio_week+str(i)] = var_ratio[i]\n",
    "\n",
    "            var_country_df[\"mean_ratio_change\"] = m_change_val\n",
    "            var_country_df[\"mean_second_ratio_derivative\"] = m_second_derivative_central\n",
    "\n",
    "            r_first = \"r_ratio_first_derivative_\"\n",
    "            for i in range(len(r_first_derivative)):\n",
    "                var_country_df[r_first+str(i)] = r_first_derivative[i]\n",
    "            var_country_df[\"mean_ratio_first_derivative\"] = r_first_derivative_mean\n",
    "\n",
    "            ### Getting the dynamics of the cases and the other variants when the variant started \n",
    "            all_cases_per_million = seq_count_period_cases[\"new_cases_per_million\"]\n",
    "            cases_per_million = var_ratio*all_cases_per_million \n",
    "            total_cases = sum(cases_per_million)\n",
    "\n",
    "            m_change_cases = mean_change(cases_per_million)\n",
    "            m_second_derivative_cases = mean_second_derivative_central(cases_per_million)\n",
    "            \n",
    "            cases_first_derivative_val = relative_first_derivative(cases_per_million)\n",
    "            cases_first_derivative_cases = cases_first_derivative_val[0]\n",
    "            cases_first_derivative_cases_mean = cases_first_derivative_val[1]\n",
    "\n",
    "            total_current_cases = all_cases_per_million.iloc[-1]\n",
    "\n",
    "            ### Enriching the table with number of cases\n",
    "            cases_week = \"cases_week_\"\n",
    "            for i in range(len(cases_per_million)):\n",
    "                var_country_df[cases_week+str(i)] = cases_per_million[i]\n",
    "\n",
    "            var_country_df[\"mean_cases_change\"] = m_change_cases\n",
    "\n",
    "            cases_first = \"cases_first_derivative_\"\n",
    "            for i in range(len(cases_first_derivative_cases)):\n",
    "                var_country_df[cases_first+str(i)] = cases_first_derivative_cases[i]\n",
    "\n",
    "            var_country_df[\"cases_mean_first_derivative\"] = cases_first_derivative_cases_mean\n",
    "            var_country_df[\"m_second_derivative_cases\"] = m_second_derivative_cases\n",
    "            var_country_df[\"total_current_cases\"] = total_current_cases\n",
    "\n",
    "            ### Observation period\n",
    "            var_country_df[\"Date - start\"] = min_date\n",
    "            var_country_df[\"Date - end\"] = max_date\n",
    "\n",
    "            return(var_country_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GISAID Variants data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/elghalizerhouni/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (16) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "### The following code takes GISAID metadata as input\n",
    "path_to_gisaid_metadata = # ADD PATH TO GISAID METADATA\n",
    "variants = pd.read_csv(path_to_gisaid_metadata, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants[\"Collection date\"] = pd.to_datetime(variants[\"Collection date\"])\n",
    "variants[\"week_date\"] = variants[\"Collection date\"].apply(lambda x: get_sunday(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants['Location_separated'] = variants['Location'].apply(lambda x: x.split(\" / \"))\n",
    "variants['continent'] = variants['Location_separated'].apply(lambda x: x[0])\n",
    "variants['country'] = variants['Location_separated'].apply(lambda x: get_country(x))\n",
    "variants['region'] = variants['Location_separated'].apply(lambda x: get_region(x))\n",
    "variants_unique = variants.drop_duplicates(subset = [\"country\", \"Pango lineage\"])\n",
    "seq_per_country = variants.groupby(\"country\")['Accession ID'].count().reset_index()\n",
    "seq_per_country = seq_per_country.sort_values(by = 'Accession ID', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the 30 countries of interest\n",
    "list_countries_oi = ['United Kingdom', 'USA', 'Germany', 'Denmark', 'Canada', 'Japan',\n",
    "       'France', 'Sweden', 'Switzerland', 'India', 'Brazil', 'Italy',\n",
    "       'Spain', 'Netherlands', 'Turkey', 'Austria', 'Belgium',\n",
    "        'Australia', 'Ireland', 'Mexico', 'Slovenia', 'Norway', 'Poland',\n",
    "        'Israel', 'South Africa', 'Lithuania', 'Portugal', 'Finland','South Korea', 'Luxembourg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 12178888 sequences in the countries of interest\n"
     ]
    }
   ],
   "source": [
    "n_sequences_per_country = variants.groupby(\"country\")['Accession ID'].count().reset_index().sort_values(by ='Accession ID', ascending = False )\n",
    "print(\"There are \" + str(n_sequences_per_country.head(30)[\"Accession ID\"].sum())+ \" sequences in the countries of interest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computing the number of sequences per variant every week in every country\n",
    "c_sequences = variants\n",
    "c_sequences['Collection date'] = pd.to_datetime(variants['Collection date'])\n",
    "c_sequences_ev = c_sequences.groupby(['country','Collection date', 'Pango lineage'])['Accession ID'].count().reset_index()\n",
    "c_sequences_ev = c_sequences_ev.rename(columns = {\"Accession ID\":\"seq_count\"})\n",
    "c_sequences_ev = c_sequences_ev[c_sequences_ev[\"Collection date\"]!=\"2020\"]\n",
    "c_sequences_ev[\"week_date\"] = c_sequences_ev[\"Collection date\"].apply(lambda x: get_sunday(x))\n",
    "\n",
    "seq_count_per_week = c_sequences_ev.groupby(['country',\"week_date\",\"Pango lineage\"])[\"seq_count\"].sum().reset_index()\n",
    "seq_count_per_week = seq_count_per_week.sort_values(by = ['country',\"week_date\"])\n",
    "\n",
    "seq_count_per_week[\"country-week_date\"] = seq_count_per_week[\"country\"]+\"//\"+seq_count_per_week[\"week_date\"].astype(\"str\")\n",
    "seq_count_per_week_pivot = seq_count_per_week.pivot(index=\"country-week_date\", columns=\"Pango lineage\", values=\"seq_count\").reset_index().fillna(0)\n",
    "seq_count_per_week_pivot[\"country\"] = seq_count_per_week_pivot[\"country-week_date\"].apply(lambda x:x.split(\"//\")[0])\n",
    "seq_count_per_week_pivot[\"week_date\"] = seq_count_per_week_pivot[\"country-week_date\"].apply(lambda x:x.split(\"//\")[1])\n",
    "seq_count_per_week_pivot = seq_count_per_week_pivot.drop(\"country-week_date\", axis = 1)\n",
    "seq_count_per_week_pivot[\"week_date\"] = pd.to_datetime(seq_count_per_week_pivot[\"week_date\"])\n",
    "\n",
    "var_col = seq_count_per_week_pivot.columns[:-2]\n",
    "seq_count_per_week_pivot[\"total_seq\"] = seq_count_per_week_pivot[var_col].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Median number of variants for the 30 most reporting country."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_variant_per_country = variants_unique.groupby(\"country\")[\"Pango lineage\"].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1878 in the world.\n"
     ]
    }
   ],
   "source": [
    "n_variants = len(variants_unique[\"Pango lineage\"].unique())\n",
    "print(\"There are \"+ str(n_variants)+\" in the world.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_30_countries = ['United Kingdom', 'USA', 'Germany', 'Denmark', 'Canada', 'Japan',\n",
    "       'France', 'Sweden', 'Switzerland', 'India', 'Brazil', 'Italy',\n",
    "       'Spain', 'Netherlands', 'Turkey', 'Austria', 'Belgium',\n",
    "        'Australia', 'Ireland', 'Mexico', 'Slovenia', 'Norway', 'Poland',\n",
    "        'Israel', 'South Africa', 'Lithuania', 'Portugal', 'Finland','South Korea', 'Luxembourg']\n",
    "top_30_countries = pd.DataFrame(top_30_countries, columns = [\"country\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_variant_top_30 = pd.merge(n_variant_per_country, top_30_countries, on = \"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a median of 490.0 in top 30 most reporting countries.\n"
     ]
    }
   ],
   "source": [
    "median = n_variant_top_30['Pango lineage'].median()\n",
    "print(\"There is a median of \"+ str(median)+\" in top 30 most reporting countries.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covid cases data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The following code take Our World in Data COVID-19 as input https://ourworldindata.org/coronavirus\n",
    "owid_path = #ADD PATH TO Our World in Data COVID-19 data\n",
    "covid_data = pd.read_csv(owid_path) \n",
    "covid_data['new_cases'] = abs(covid_data['new_cases'])\n",
    "covid_data['new_cases_per_million'] = abs(covid_data['new_cases_per_million'])\n",
    "covid_data[\"date\"] = pd.to_datetime(covid_data[\"date\"])\n",
    "covid_data[\"week_date\"] = covid_data[\"date\"].apply(lambda x: get_sunday(x))\n",
    "covid_data = covid_data.fillna(0)\n",
    "global_cases = covid_data.groupby([\"week_date\", \"location\"])['new_cases_per_million'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_cases[\"country\"] = global_cases[\"location\"].replace(\"United States\", \"USA\")\n",
    "global_cases[\"country\"] = global_cases[\"country\"].replace('Czechia', \"Czech Republic\")\n",
    "global_cases = global_cases[[\"week_date\",\"country\",'new_cases_per_million']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_count_per_week_cases_pivot = pd.merge(seq_count_per_week_pivot, global_cases, on = [\"week_date\",\"country\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1878 variants following the Pango lineage\n"
     ]
    }
   ],
   "source": [
    "### Number of variants\n",
    "n_variants = len(variants['Pango lineage'].unique())\n",
    "print(\"There are \" + str(n_variants) + \" variants following the Pango lineage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Number of variants per country\n",
    "unique_variants_per_country = variants.drop_duplicates(['country','Pango lineage'])\n",
    "n_variants_per_country = unique_variants_per_country.groupby(\"country\")['Pango lineage'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_seq_country = variants.groupby(\"country\")['Accession ID'].count().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 220 locations\n"
     ]
    }
   ],
   "source": [
    "n_locations = len(n_variants_per_country[\"country\"].unique())\n",
    "print(\"There are \" + str(n_locations) + \" locations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a median of 65.5 variants per location\n"
     ]
    }
   ],
   "source": [
    "median_variants = n_variants_per_country[\"Pango lineage\"].median()\n",
    "print(\"There is a median of \" + str(median_variants) + \" variants per location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters to compute independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_weeks = 2 #Indicate the number of weeks of the observation period\n",
    "threshold_substitution = 0.10 #Some mutations don't appear in all sequences of the same variant. This threshold indicate the minimum proportion of sequences that a mutation needs to be identified in to consider it\n",
    "threshold_seq = 5 #Indicate the minimum number of sequences of variant to consider it during a week"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variants biological evolution features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the biological features for every variant in every country, starting by the United Kingdom\n",
    "country = \"United Kingdom\"\n",
    "variants_country = variants[(variants[\"country\"] == country) & (variants[\"week_date\"]>\"2020-02-01\")]\n",
    "c_sequences = variants_country[variants_country[\"Collection date\"]!=\"2020\"]\n",
    "seq_count_per_week = c_sequences.groupby([\"week_date\",\"Pango lineage\"])['Accession ID'].count().reset_index()\n",
    "seq_count_per_week = seq_count_per_week.rename(columns = {\"Accession ID\":\"seq_count\"})\n",
    "seq_count_per_week = seq_count_per_week.sort_values(by = [\"week_date\"])\n",
    "seq_count_per_week_pivot = seq_count_per_week.pivot(index=\"week_date\", columns=\"Pango lineage\", values=\"seq_count\").reset_index().fillna(0)\n",
    "variants_list = list(variants_country[\"Pango lineage\"].dropna().unique())\n",
    "country_cases = global_cases[global_cases[\"country\"] == country]\n",
    "\n",
    "var = variants_list[0]\n",
    "c = country\n",
    "biological_evolution_country = get_biological_evolution(c, variants_country,seq_count_per_week_pivot,var,n_weeks,threshold_substitution, threshold_seq, country_cases)\n",
    "for var in variants_list[1:]:\n",
    "    biological_evolution = get_biological_evolution(c, variants_country,seq_count_per_week_pivot,var,n_weeks,threshold_substitution, threshold_seq, country_cases)\n",
    "    biological_evolution_country = pd.concat([biological_evolution_country,biological_evolution], axis = 0)\n",
    "\n",
    "biological_evolution_country = biological_evolution_country[biological_evolution_country[\"Date - start\"].isna() == False].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries_list = [c for c in list_countries_oi if c != \"United Kingdom\"]\n",
    "\n",
    "for c in countries_list:\n",
    "    print(c)\n",
    "    variants_country = variants[(variants[\"country\"] == c) & (variants[\"week_date\"]>\"2020-02-01\")]\n",
    "    c_sequences = variants_country[variants_country[\"Collection date\"]!=\"2020\"]\n",
    "    seq_count_per_week = c_sequences.groupby([\"week_date\",\"Pango lineage\"])['Accession ID'].count().reset_index()\n",
    "    seq_count_per_week = seq_count_per_week.rename(columns = {\"Accession ID\":\"seq_count\"})\n",
    "    seq_count_per_week = seq_count_per_week.sort_values(by = [\"week_date\"])\n",
    "    seq_count_per_week_pivot = seq_count_per_week.pivot(index=\"week_date\", columns=\"Pango lineage\", values=\"seq_count\").reset_index().fillna(0)\n",
    "    variants_list = list(variants_country[\"Pango lineage\"].dropna().unique())\n",
    "    variants_list = [v for v in variants_list if v!= \"None\"]\n",
    "    \n",
    "    country_cases = global_cases[global_cases[\"country\"] == c]\n",
    "    if len(country_cases)>0:\n",
    "        var = variants_list[0]\n",
    "        biological_evolution_loc = get_biological_evolution(c, variants_country,seq_count_per_week_pivot,var,n_weeks,threshold_substitution, threshold_seq, country_cases)\n",
    "\n",
    "        for var in variants_list[1:]:\n",
    "            biological_evolution = get_biological_evolution(c, variants_country,seq_count_per_week_pivot,var,n_weeks,threshold_substitution, threshold_seq, country_cases)\n",
    "            biological_evolution = biological_evolution.fillna(0)\n",
    "            biological_evolution_loc = pd.concat([biological_evolution_loc,biological_evolution], axis = 0)\n",
    "\n",
    "        biological_evolution_country = pd.concat([biological_evolution_country,biological_evolution_loc], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "biological_evolution_all = biological_evolution_country\n",
    "biological_evolution_all = biological_evolution_all[biological_evolution_all[\"Date - end\"].isna() == False]\n",
    "biological_evolution_all = biological_evolution_all.fillna(0)\n",
    "biological_evolution_all.to_csv(\"generated_data/biological_evolution_country_\"+str(n_weeks)+\"weeks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "biological_evolution_all = pd.read_csv(\"generated_data/biological_evolution_country_\"+str(n_weeks)+\"weeks.csv\").drop(\"Unnamed: 0\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation of the number of mutations per viral protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Isolating biological features\n",
    "list_var_col = ['variant','cases_first_derivative_0',\n",
    "       'cases_first_derivative_1', 'cases_first_derivative_2','cases_mean_first_derivative', 'cases_week_0', 'cases_week_1','cases_week_2', 'cases_week_3', 'country', 'dominant_1', 'dominant_2','m_second_derivative_cases', 'mean_cases_change', 'mean_ratio_change',\n",
    "       'mean_ratio_first_derivative', 'mean_second_ratio_derivative','prop_dominant_1', 'prop_dominant_2', 'r_ratio_first_derivative_0','r_ratio_first_derivative_1', 'r_ratio_first_derivative_2', 'ratio_week_0', 'ratio_week_1', 'ratio_week_2', 'ratio_week_3', 'total_current_cases', 'variants_entropy', 'number_of_mutation', 'difference_from_dom',   'current_new_cases_per_million',\n",
    "       'current_total_vaccinations_per_hundred', 'current_stringency_index',\n",
    "        \"max_week_cases\", \"n_variants_past\",\"cancel_public_events\",'restriction_gatherings','Date - start', 'Date - end', '']\n",
    "all_col = biological_evolution_all.columns\n",
    "bio_col = [c for c in all_col if (c not in list_var_col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Getting the number of mutations per protein\n",
    "\n",
    "### Non-structural protein\n",
    "NSP_list = []\n",
    "### N protein\n",
    "N_list = []\n",
    "### Spike protein\n",
    "Spike_list = []\n",
    "### M protein\n",
    "M_list = []\n",
    "### E protein\n",
    "E_list = []\n",
    "\n",
    "other_list = []\n",
    "\n",
    "for col in bio_col:\n",
    "    if col[0:3] == 'NSP' or col[0:2] == 'NS':\n",
    "        NSP_list+=[col]\n",
    "    elif col[0:5] == 'Spike':\n",
    "        Spike_list += [col]\n",
    "    elif col[0] == 'N':\n",
    "        N_list += [col]\n",
    "    elif col[0] == 'M':\n",
    "        M_list += [col]\n",
    "    elif col[0] == 'E':\n",
    "        E_list += [col]\n",
    "        \n",
    "biological_evolution_all[\"total_number_of_mutations\"] = biological_evolution_all[bio_col].sum(axis = 1)\n",
    "biological_evolution_all[\"NSP_mutations\"] = biological_evolution_all[NSP_list].sum(axis = 1)\n",
    "biological_evolution_all[\"Spike_mutations\"] = biological_evolution_all[Spike_list].sum(axis = 1)\n",
    "biological_evolution_all[\"N_mutations\"] = biological_evolution_all[N_list].sum(axis = 1)\n",
    "biological_evolution_all[\"M_mutations\"] = biological_evolution_all[M_list].sum(axis = 1)\n",
    "biological_evolution_all[\"E_mutations\"] = biological_evolution_all[E_list].sum(axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing Jaccard and absolute distance between variant and the dominant variant during the observation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Computing Jaccard and absolute distance between variant and the dominant variant during the observation period\n",
    "\n",
    "country_list = list(biological_evolution_all[\"country\"].unique())\n",
    "c = country_list[0]\n",
    "country_variants = biological_evolution_all[biological_evolution_all[\"country\"] == c]\n",
    "n_var = len(country_variants)\n",
    "absolute_distance_list = []\n",
    "jaccard_distance_list = []\n",
    "for i in range(n_var):\n",
    "    var_data = country_variants.iloc[i]\n",
    "    dom = var_data[\"dominant_1\"]\n",
    "    dom_data = country_variants[country_variants[\"variant\"] == dom]\n",
    "    bio_var_1 = list(np.array(var_data[bio_col])[1:])\n",
    "    bio_var_2 = list(np.array(dom_data[bio_col])[0][1:])\n",
    "    absolute_distance_v = absolute_distance(bio_var_1, bio_var_2)\n",
    "    jaccard_distance_v = jaccard_distance(bio_var_1, bio_var_2)\n",
    "    absolute_distance_list +=[absolute_distance_v]\n",
    "    jaccard_distance_list +=[jaccard_distance_v]\n",
    "\n",
    "country_variants[\"absolute_distance\"] = absolute_distance_list\n",
    "country_variants[\"jaccard_distance\"] = jaccard_distance_list\n",
    "\n",
    "for c in country_list[1:]:\n",
    "    country_variants_loc = biological_evolution_all[biological_evolution_all[\"country\"] == c]\n",
    "    n_var = len(country_variants_loc)\n",
    "    absolute_distance_list = []\n",
    "    jaccard_distance_list = []\n",
    "    for i in range(n_var):\n",
    "        var_data = country_variants_loc.iloc[i]\n",
    "        dom = var_data[\"dominant_1\"]\n",
    "        dom_data = country_variants_loc[country_variants_loc[\"variant\"] == dom]\n",
    "        if len(dom_data)>0:\n",
    "            bio_var_1 = list(np.array(var_data[bio_col])[1:])\n",
    "            bio_var_2 = list(np.array(dom_data[bio_col])[0][1:])\n",
    "            absolute_distance_v = absolute_distance(bio_var_1, bio_var_2)\n",
    "            jaccard_distance_v = jaccard_distance(bio_var_1, bio_var_2)\n",
    "            absolute_distance_list +=[absolute_distance_v]\n",
    "            jaccard_distance_list +=[jaccard_distance_v]\n",
    "        else:\n",
    "            absolute_distance_list +=[0]\n",
    "            jaccard_distance_list +=[0]\n",
    "    country_variants_loc[\"absolute_distance\"] = absolute_distance_list\n",
    "    country_variants_loc[\"jaccard_distance\"] = jaccard_distance_list\n",
    "    \n",
    "    country_variants = pd.concat([country_variants,country_variants_loc], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_variants.to_csv(\"generated_data/country_variants\"+str(n_weeks)+\"weeks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing the heterogeneity during observation period of each variant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_variants[\"Date - start\"] = pd.to_datetime(country_variants[\"Date - start\"])\n",
    "country_variants[\"Date - end\"] = pd.to_datetime(country_variants[\"Date - end\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Country variants\n",
    "country_list = list(country_variants[\"country\"].unique())\n",
    "heterogeneity_country_all = []\n",
    "\n",
    "for country in country_list:\n",
    "    country_variant_data = country_variants[country_variants[\"country\"] == country]\n",
    "    bio_col = country_variant_data.columns[2:-9]\n",
    "\n",
    "    ### Country sequences\n",
    "    seq_country = seq_count_per_week_cases_pivot[seq_count_per_week_cases_pivot[\"country\"]== country] #.head(10)\n",
    "\n",
    "    ### Hetereogeneity measure for each variant during observation period\n",
    "    heterogeneity_country = []\n",
    "    n_country_var = len(country_variant_data)\n",
    "\n",
    "    for k in range(n_country_var):\n",
    "        country_var = country_variant_data.iloc[k]\n",
    "        date_start = country_var[\"Date - start\"] + datetime.timedelta(days=-7)\n",
    "        date_end = country_var[\"Date - end\"]\n",
    "        seq_country_period = seq_country[(seq_country[\"week_date\"] >= date_start) & (seq_country[\"week_date\"] <= date_end)]\n",
    "        var_col = seq_country.columns[:-4]\n",
    "        seq_per_var = seq_country_period[var_col].sum(axis = 0).sort_values(ascending = False)\n",
    "        total_seq = seq_country_period[\"total_seq\"].sum(axis = 0)\n",
    "        ratio_per_var = seq_per_var/total_seq \n",
    "        ratio_per_var_df = pd.DataFrame(ratio_per_var.head(10)).reset_index().rename(columns = {0:\"ratio\"})\n",
    "        variants_index = ratio_per_var_df[\"index\"]\n",
    "        ratios = ratio_per_var_df[\"ratio\"]\n",
    "        variants_list = list(country_variant_data[\"variant\"])\n",
    "\n",
    "        variants_in = []\n",
    "        ratios_in = []\n",
    "        for k in range(10):\n",
    "            if variants_index[k] in variants_list:\n",
    "                variants_in += [variants_index[k]]\n",
    "                ratios_in += [ratios[k]]\n",
    "\n",
    "        n_var = len(variants_in)\n",
    "        heterogeneity = 0\n",
    "        R = 0\n",
    "\n",
    "        for i in range(n_var):\n",
    "            for j in range(n_var):\n",
    "                var_1 = variants_in[i]\n",
    "                r_1 = ratios_in[i]\n",
    "                var_2 = variants_in[j]\n",
    "                r_2 = ratios_in[j]\n",
    "\n",
    "                var_info_1 = country_variant_data[(country_variant_data[\"variant\"] == var_1)][bio_col].values[0]\n",
    "                var_info_2 = country_variant_data[(country_variant_data[\"variant\"] == var_2)][bio_col].values[0]\n",
    "\n",
    "                j_d = jaccard_distance(var_info_1,var_info_2)\n",
    "                heterogeneity += r_1*r_2*j_d\n",
    "                R += r_1*r_2\n",
    "\n",
    "        heterogeneity_country += [heterogeneity]   \n",
    "    heterogeneity_country_all += heterogeneity_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_variants[\"heterogeneity\"] = heterogeneity_country_all\n",
    "country_variants.to_csv(\"generated_data/country_variants\"+str(n_weeks)+\"weeks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemiological evolution and restriction features during obervation period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_variants = country_variants.drop_duplicates(subset = [\"country\", \"variant\", \"Date - start\", \"Date - end\"])\n",
    "country_variants[\"Date - end\"] = pd.to_datetime(country_variants[\"Date - end\"])\n",
    "country_variants[\"Date - start\"] = pd.to_datetime(country_variants[\"Date - start\"])\n",
    "country_variants[\"time_period\"] = (country_variants[\"Date - end\"] - country_variants[\"Date - start\"]).dt.days\n",
    "country_variants = country_variants[country_variants[\"time_period\"] == n_weeks*7]\n",
    "\n",
    "weekly_cases = covid_data.groupby([\"week_date\", \"location\"])['new_cases_per_million'].sum().reset_index()\n",
    "weekly_mean_total_vaccinations = covid_data.groupby([\"week_date\", \"location\"])['total_vaccinations_per_hundred'].mean().reset_index()\n",
    "weekly_stringency = covid_data.groupby([\"week_date\", \"location\"])[\"stringency_index\"].mean().reset_index()\n",
    "case_vacc = pd.merge(weekly_cases,weekly_mean_total_vaccinations, on =  [\"week_date\", \"location\"])\n",
    "case_vacc_stringency = pd.merge(case_vacc,weekly_stringency, on =  [\"week_date\", \"location\"]).rename(columns = {\"location\":\"country\"})\n",
    "case_vacc_stringency[\"week_date\"] = pd.to_datetime(case_vacc_stringency[\"week_date\"])\n",
    "case_vacc_stringency[\"country\"] = case_vacc_stringency[\"country\"].replace(\"United States\",\"USA\")\n",
    "\n",
    "epidemiology_situation = pd.merge(country_variants[[\"variant\", \"country\", \"Date - end\"]], case_vacc_stringency, left_on = [\"Date - end\", \"country\"], right_on = [\"week_date\", \"country\"], how = \"left\")\n",
    "\n",
    "col = ['variant', 'country', 'Date - end',  'new_cases_per_million', 'total_vaccinations_per_hundred','stringency_index']\n",
    "\n",
    "epidemiology_situation = epidemiology_situation[col].rename(columns = {\"new_cases_per_million\":\"current_new_cases_per_million\", \"total_vaccinations_per_hundred\":\"current_total_vaccinations_per_hundred\", \"stringency_index\":\"current_stringency_index\"})\n",
    "\n",
    "country_variants_epi = pd.merge(country_variants, epidemiology_situation, on = ['variant', 'country', 'Date - end'], how = \"inner\")\n",
    "\n",
    "all_indep_variables_oi = country_variants_epi[[\"country\", \"variant\", \"Date - end\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Propagration in other countries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = country_variants_epi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_cases_l = [\"cases_week_1\", \"cases_week_2\",\"cases_week_3\",\"cases_week_4\"]\n",
    "last_cases = last_cases_l[n_weeks-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_countries_var = len(data)\n",
    "max_week_cases_l = []\n",
    "n_countries_l = []\n",
    "max_cumulative_country_l = []\n",
    "max_cumulative_mean_country_l = []\n",
    "\n",
    "for i in range(n_countries_var):\n",
    "    data_loc = data.iloc[i]\n",
    "    var = data_loc[\"variant\"]\n",
    "    country = data_loc[\"country\"]\n",
    "    date_end = data_loc[\"Date - end\"]\n",
    "\n",
    "    var_in_other_countries = data[(data[\"variant\"] == var) & (data[\"Date - start\"] <= date_end) & (data[\"country\"] != country)]\n",
    "    countries_oi = var_in_other_countries[[\"Date - start\",\"country\",\"variant\",last_cases]][\"country\"]\n",
    "    other_countries_seq = pd.merge(seq_count_per_week_cases_pivot,countries_oi, on = \"country\")\n",
    "    other_countries_seq_oi = other_countries_seq[[var, \"country\", \"week_date\", \"total_seq\", \"new_cases_per_million\"]]\n",
    "    other_countries_seq_oi = other_countries_seq_oi[other_countries_seq_oi[\"week_date\"] <= date_end]\n",
    "    other_countries_seq_oi[\"ratio_var\"] = other_countries_seq_oi[var]/other_countries_seq_oi[\"total_seq\"]\n",
    "    other_countries_seq_oi[\"cases_var\"] = other_countries_seq_oi[\"ratio_var\"]*other_countries_seq_oi[\"new_cases_per_million\"]\n",
    "    \n",
    "    cumulative_country = other_countries_seq_oi.groupby(\"country\")[\"cases_var\"].sum().reset_index()\n",
    "    mean_country = other_countries_seq_oi.groupby(\"country\")[\"cases_var\"].mean().reset_index()\n",
    "    \n",
    "    max_cumulative_mean_country = mean_country[\"cases_var\"].max()\n",
    "    max_cumulative_country = cumulative_country[\"cases_var\"].max()\n",
    "    max_week_cases = other_countries_seq_oi[\"cases_var\"].max()\n",
    "    n_countries = len(countries_oi)\n",
    "\n",
    "    max_cumulative_mean_country_l += [max_cumulative_mean_country]\n",
    "    max_week_cases_l += [max_week_cases]\n",
    "    n_countries_l += [n_countries]\n",
    "    max_cumulative_country_l += [max_cumulative_country]\n",
    "    \n",
    "data[\"max_cumulative_mean_country\"] = max_cumulative_mean_country_l\n",
    "data[\"max_week_cases\"] = max_week_cases_l\n",
    "data[\"max_cumulative_country\"] = max_cumulative_country_l\n",
    "data[\"n_countries\"] = n_countries_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"generated_data/data_indep_other_countries_\"+str(n_weeks)+\"_weeks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_l = list(data[\"country\"].unique())\n",
    "n_variants_l = []\n",
    "for c in country_l:\n",
    "    data_country = data[data[\"country\"] == c]\n",
    "    n_country = len(data_country)\n",
    "    for i in range(n_country):\n",
    "        data_country_loc = data_country.iloc[i]\n",
    "        var = data_country_loc[\"variant\"]\n",
    "        date_end = data_country_loc[\"Date - end\"]\n",
    "        n_variants = len(data_country[data_country[\"Date - start\"] <= date_end])\n",
    "        n_variants_l +=[n_variants]\n",
    "data[\"n_variants_past\"] = n_variants_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(\"generated_data/data_indep_other_countries_\"+str(n_weeks)+\"_weeks.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Social restriction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrictions on public events\n",
    "mobility_data_path = #PATH TO MOBILITY DATA FROM OUR WORLD IN DATA\n",
    "public_events = pd.read_csv(mobility_data_path)\n",
    "public_events = public_events.rename(columns = {\"Day\":\"date\", \"Entity\":\"country\"})\n",
    "public_events[\"date\"] = pd.to_datetime(public_events[\"date\"])\n",
    "public_events[\"week_date\"] = public_events[\"date\"].apply(lambda x: get_sunday(x))\n",
    "public_events[\"country\"] = public_events[\"country\"].replace(\"United States\", \"USA\")\n",
    "public_events_country = public_events.groupby([\"country\", \"week_date\"])['cancel_public_events'].mean().reset_index()\n",
    "data_public = pd.merge(data,public_events_country, left_on = [\"country\", \"Date - end\"], right_on = [\"country\", \"week_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Restrictions on social gathering\n",
    "gathering_data_path = #PATH TO PUBLIC GATHERING DATA FROM OUR WORLD IN DATA\n",
    "social_gathering = pd.read_csv(gathering_data_path)\n",
    "social_gathering = social_gathering.rename(columns = {\"Day\":\"date\", \"Entity\":\"country\"})\n",
    "social_gathering[\"date\"] = pd.to_datetime(social_gathering[\"date\"])\n",
    "social_gathering[\"country\"] = social_gathering[\"country\"].replace(\"United States\", \"USA\")\n",
    "social_gathering[\"week_date\"] = social_gathering[\"date\"].apply(lambda x: get_sunday(x))\n",
    "social_gathering_country = social_gathering.groupby([\"country\", \"week_date\"])[\"restriction_gatherings\"].mean().reset_index()\n",
    "data_public_social_d = pd.merge(data_public,social_gathering_country, left_on = [\"country\", \"Date - end\"], right_on = [\"country\", \"week_date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_public_social_d.to_csv(\"generated_data/data_public_social_d_\"+str(n_weeks)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vaccinations data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekly_mean_total_vaccinations = covid_data.groupby([\"week_date\", \"location\"])['people_vaccinated_per_hundred'].mean().reset_index().rename(columns = {\"location\":\"country\"})\n",
    "weekly_mean_total_vaccinations[\"country\"] = weekly_mean_total_vaccinations[\"country\"].replace(\"United States\",\"USA\")\n",
    "\n",
    "epidemiology_situation = pd.merge(data_public_social_d[[\"variant\", \"country\", \"Date - end\"]], weekly_mean_total_vaccinations, left_on = [\"Date - end\", \"country\"], right_on = [\"week_date\", \"country\"], how = \"left\")\n",
    "\n",
    "col = ['variant', 'country', 'Date - end', 'people_vaccinated_per_hundred']\n",
    "\n",
    "epidemiology_situation = epidemiology_situation[col].rename(columns = {\"new_cases_per_million\":\"current_new_cases_per_million\", \"total_vaccinations_per_hundred\":\"current_total_vaccinations_per_hundred\"})\n",
    "\n",
    "data_public_social_d_epi = pd.merge(data_public_social_d, epidemiology_situation, on = ['variant', 'country', 'Date - end'], how = \"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_public_social_d_epi.to_csv(\"generated_data/data_public_social_timing_vax_\"+str(n_weeks)+\".csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding dependent variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### The dependent variable is the number of cases that each variant in each country in the next 1 month, 2 months, 3 months\n",
    "def get_dep_var(c):\n",
    "    variants_country = variants[(variants[\"country\"] == c) & (variants[\"week_date\"]>\"2020-02-01\")]\n",
    "    c_sequences = variants_country[variants_country[\"Collection date\"]!=\"2020\"]\n",
    "    seq_count_per_week = c_sequences.groupby([\"week_date\",\"Pango lineage\"])['Accession ID'].count().reset_index()\n",
    "    seq_count_per_week = seq_count_per_week.rename(columns = {\"Accession ID\":\"seq_count\"})\n",
    "    seq_count_per_week = seq_count_per_week.sort_values(by = [\"week_date\"])\n",
    "    seq_count_per_week_pivot = seq_count_per_week.pivot(index=\"week_date\", columns=\"Pango lineage\", values=\"seq_count\").reset_index().fillna(0)\n",
    "    variants_list = list(variants_country[\"Pango lineage\"].dropna().unique())\n",
    "    variants_list = [v for v in variants_list if v!= \"None\"]\n",
    "\n",
    "    country_cases = global_cases[global_cases[\"country\"] == c]\n",
    "\n",
    "    bio_col = seq_count_per_week_pivot.columns[2:]\n",
    "    seq_count_per_week_pivot[\"tot_seq\"] = seq_count_per_week_pivot[bio_col].sum(axis = 1)\n",
    "    seq_cases = pd.merge(seq_count_per_week_pivot,country_cases, on = [\"week_date\"])\n",
    "\n",
    "    dep_var = []\n",
    "    all_indep_variables_country = all_indep_variables_oi[all_indep_variables_oi[\"country\"] == c]\n",
    "    n_var_c = len(all_indep_variables_country)\n",
    "    for i in range(n_var_c):\n",
    "        var_country = all_indep_variables_country.iloc[i]\n",
    "        var = var_country[\"variant\"]\n",
    "        date_end = var_country[\"Date - end\"]\n",
    "        \n",
    "        ### Assessment after 3 months\n",
    "        date_month_3 = date_end+datetime.timedelta(days=3*28)\n",
    "        seq_count_period_3 = seq_cases[(seq_cases[\"week_date\"]>= date_end) & (seq_cases[\"week_date\"]<= date_month_3)]\n",
    "        seq_count_period_3_sum = seq_count_period_3.sum(axis = 0)\n",
    "        ratio_month_3 = seq_count_period_3_sum[var]/seq_count_period_3_sum[\"tot_seq\"]\n",
    "        count_month_3 = ratio_month_3*seq_count_period_3_sum[\"new_cases_per_million\"]\n",
    "\n",
    "        ### Assessment after 2 months\n",
    "        date_month_2 = date_end+datetime.timedelta(days=2*28)\n",
    "        seq_count_period_2 = seq_cases[(seq_cases[\"week_date\"]>= date_end) & (seq_cases[\"week_date\"]<= date_month_2)]\n",
    "        seq_count_period_2_sum = seq_count_period_2.sum(axis = 0)\n",
    "        ratio_month_2 = seq_count_period_2_sum[var]/seq_count_period_2_sum[\"tot_seq\"]\n",
    "        count_month_2 = ratio_month_2*seq_count_period_2_sum[\"new_cases_per_million\"]\n",
    "\n",
    "        ### Assessment after 1 month\n",
    "        date_month_1 = date_end+datetime.timedelta(days=28)\n",
    "        seq_count_period_1 = seq_cases[(seq_cases[\"week_date\"]>= date_end) & (seq_cases[\"week_date\"]<= date_month_1)]\n",
    "        seq_count_period_1_sum = seq_count_period_1.sum(axis = 0)\n",
    "        ratio_month_1 = seq_count_period_1_sum[var]/seq_count_period_1_sum[\"tot_seq\"]\n",
    "        count_month_1 = ratio_month_1*seq_count_period_1_sum[\"new_cases_per_million\"]\n",
    "        \n",
    "        dep_var += [[c, var, date_end, ratio_month_3, count_month_3, ratio_month_2, count_month_2, ratio_month_1, count_month_1]]\n",
    "        \n",
    "    dep_var_df = pd.DataFrame(dep_var, columns = [\"country\",\"var\",\"date_end\",\"ratio_month_3\", \"count_month_3\", \"ratio_month_2\", \"count_month_2\", \"ratio_month_1\", \"count_month_1\"])\n",
    "    return(dep_var_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_list = list(all_indep_variables_oi[\"country\"].unique())\n",
    "c = country_list[0]\n",
    "dep_var_df_global = get_dep_var(c)\n",
    "\n",
    "for c in country_list[1:]:\n",
    "    dep_var_df = get_dep_var(c)\n",
    "    dep_var_df_global = pd.concat([dep_var_df_global,dep_var_df], axis = 0)\n",
    "\n",
    "dep_var_df_global.to_csv(\"generated_data/dep_var_df_global_\"+str(n_weeks)+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Merging the dependent and independent variables\n",
    "dep_var_df_global = dep_var_df_global.rename(columns = {\"var\":\"variant\",\"date_end\":\"Date - end\"})\n",
    "dep_var_df_global[\"Date - end\"] = pd.to_datetime(dep_var_df_global[\"Date - end\"])\n",
    "data_indep_dep = pd.merge(data_public_social_d_epi, dep_var_df_global, on = [\"variant\", \"country\", \"Date - end\" ])\n",
    "data_indep_dep.to_csv(\"generated_data/data_indep_dep_\"+str(n_weeks)+\"_weeks.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
